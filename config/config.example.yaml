# Example configuration for code-cli-any-llm
# Copy this file to config.yaml and modify as needed for project-specific settings

# Active provider: 'openai', 'codex' 或 'claudeCode'
aiProvider: claudeCode

# API Configuration
openai:
  apiKey: 'your-api-key-here'
  baseURL: 'https://open.bigmodel.cn/api/paas/v4'  # 智谱AI endpoint
  model: 'glm-4.5'  # Default model
  timeout: 1800000
  # Extra body parameters that will be added to the API request
  # Useful for provider-specific parameters like max_input_tokens for qwen models
  extraBody:
    # For qwen-plus models, set max_input_tokens to increase input limit
    # qwen-plus-latest: default 129,024, can be extended to 1,000,000
    # qwen-plus-2025-07-28: default 1,000,000
    max_input_tokens: 200000  # Increase input token limit

# Codex configuration (optional, only used when aiProvider is set to codex)
codex:
  apiKey: ''
  baseURL: 'https://chatgpt.com/backend-api/codex'
  model: 'gpt-5-codex'
  timeout: 1800000
  # reasoning.effort 控制推理 token 数量，可选 minimal/low/medium/high；默认 medium。
  # 设置为 minimal 可显著降低延迟与推理 token 使用量（参考 OpenAI 最新模型指南）。
  reasoning:
    effort: minimal
    summary: auto
  # textVerbosity 控制回复详略程度，可选 low/medium/high；默认 medium。
  # 较低值可得到更简洁的输出，适合追求低延迟或精简代码生成的场景。
  textVerbosity: low

# Claude Code configuration (optional, only used when aiProvider is set to claudeCode)
claudeCode:
  apiKey: ''
  baseURL: 'https://open.bigmodel.cn/api/anthropic'
  model: 'claude-sonnet-4-5-20250929'
  timeout: 1800000
  anthropicVersion: '2023-06-01'
  beta:
    - claude-code-20250219
  userAgent: 'claude-cli/2.0.1 (external, cli)'
  xApp: 'cli'
  dangerousDirectBrowserAccess: true
  maxOutputTokens: 64000
  # extraHeaders 可用于追加额外的 HTTP 请求头（键值对形式）
  extraHeaders: {}

# Gateway Configuration
gateway:
  port: 23062
  host: '0.0.0.0'
  logLevel: 'info'
  logDir: '~/.code-cli-any-llm/logs'
  requestTimeout: 3600000
  apiMode: gemini   # 可选 gemini / openai
  cliMode: gemini   # 可选 gemini / opencode / crush / qwencode
  apiKey: ''        # 可选：提供给 CLI 网关的访问密钥
