# Example configuration for gemini-any-llm
# Copy this file to config.yaml and modify as needed for project-specific settings

# Active provider: 'openai', 'codex' 或 'claudeCode'
aiProvider: claudeCode

# API Configuration
openai:
  apiKey: 'your-api-key-here'
  baseURL: 'https://open.bigmodel.cn/api/paas/v4'  # 智谱AI endpoint
  model: 'glm-4.5'  # Default model
  timeout: 30000
  # Extra body parameters that will be added to the API request
  # Useful for provider-specific parameters like max_input_tokens for qwen models
  extraBody:
    # For qwen-plus models, set max_input_tokens to increase input limit
    # qwen-plus-latest: default 129,024, can be extended to 1,000,000
    # qwen-plus-2025-07-28: default 1,000,000
    max_input_tokens: 200000  # Increase input token limit

# Codex configuration (optional, only used when aiProvider is set to codex)
codex:
  apiKey: ''
  baseURL: 'https://chatgpt.com/backend-api/codex'
  model: 'gpt-5-codex'
  timeout: 60000
  # reasoning.effort 控制推理 token 数量，可选 minimal/low/medium/high；默认 medium。
  # 设置为 minimal 可显著降低延迟与推理 token 使用量（参考 OpenAI 最新模型指南）。
  reasoning:
    effort: minimal
    summary: auto
  # textVerbosity 控制回复详略程度，可选 low/medium/high；默认 medium。
  # 较低值可得到更简洁的输出，适合追求低延迟或精简代码生成的场景。
  textVerbosity: low

# Claude Code configuration (optional, only used when aiProvider is set to claudeCode)
claudeCode:
  apiKey: ''
  baseURL: 'https://open.bigmodel.cn/api/anthropic'
  model: 'claude-sonnet-4-20250514'
  timeout: 60000
  anthropicVersion: '2023-06-01'
  beta:
    - claude-code-20250219
    - interleaved-thinking-2025-05-14
    - fine-grained-tool-streaming-2025-05-14
  userAgent: 'claude-cli/1.0.119 (external, cli)'
  xApp: 'cli'
  dangerousDirectBrowserAccess: true
  maxOutputTokens: 64000
  # extraHeaders 可用于追加额外的 HTTP 请求头（键值对形式）
  extraHeaders: {}

# Gateway Configuration
gateway:
  port: 23062
  host: '0.0.0.0'
  logLevel: 'info'
  logDir: '~/.gemini-any-llm/logs'
