Usage: cal [command]

Gemini Any LLM assistant tool - provides an optimized AI chat experience through the local gateway

Commands:
  code [prompt]     Chat with the AI assistant (primary command)
                    • Send questions or tasks to the assistant directly
                    • Automatically starts and manages the background gateway service
                    • Supports all native options and flags from the gemini CLI
                    • Guides you through configuring credentials on first use
                    • Alerts you about new versions before upgrading
                    • Use `--cli-mode opencode|crush|gemini` to switch CLI AI Code CLI Tool

  auth              Configure AI service credentials
                    • Supports providers claudeCode / codex / openai
                    • Interactively sets API keys, base URLs, and default models
                    • Configuration file: ~/.code-cli-any-llm/config.yaml
                    • Run this the first time or when switching providers

  update            Check for and install the latest version
                    • Refreshes the version cache and runs the upgrade command
                    • Exits after informing you if you already have the latest version

  version           Show the current cal version
  help              Show this help in English (aliases: -h, --help)
  help-cn           Show this help in Chinese (alias: --help-cn)
  -v, --version     Show the current cal version (alias of version)

Gateway management commands:
  start             Start the background gateway service
                    • Manual start, usually not needed directly
                    • Detects existing processes to avoid duplicates
                    • Waits for the health check before returning

  stop              Stop the background gateway service
                    • Gracefully shuts down the gateway and cleans resources
                    • Waits for processes to exit (10 second timeout)

  restart           Restart the gateway service
                    • Performs a full stop followed by a fresh start
                    • Recommended after configuration changes

  status            Show gateway status
                    • Displays health and connection information
                    • Shows process details and provider configuration

  kill              Force terminate stuck processes (troubleshooting)
                    • Tries multiple methods to find and kill zombie processes
                    • Use only when the gateway becomes unresponsive

Configuration & environment:
  • Config file: ~/.code-cli-any-llm/config.yaml
  • Default gateway port: 23062 (changeable in the config file)
  • PID file: ~/.code-cli-any-llm/gateway.pid.json
  • Disable automatic update checks: set GAL_DISABLE_UPDATE_CHECK=1

Usage examples:
  # First run: configure credentials
  cal auth

  # Chat with the AI assistant (primary usage)
  cal code "Write an HTTP server in TypeScript"
  cal code "Explain what this code does"
  cal code "Help me optimize this algorithm"
  
  # View additional gemini CLI options
  cal code --help
  
  # Advanced operations (rarely needed)
  cal status         # Check gateway status
  cal restart        # Restart after config changes
  cal kill           # Troubleshoot stuck processes

Troubleshooting:
  • Assistant not responding: run 'cal kill' to clean up and try again
  • Authentication failure: run 'cal auth' to reconfigure the API key
  • Service fails to start: check network connectivity and port usage
  • Configuration issues: inspect ~/.code-cli-any-llm/config.yaml
  • Permission issues: ensure read/write access to ~/.code-cli-any-llm/
